\documentclass[12pt,a4paper]{article}

%%  Стандартные языковые команды
%% Стандартные языковые команды
\usepackage[T2A]{fontenc}        % ← КЛЮЧЕВАЯ СТРОКА!
\usepackage[utf8]{inputenc}      % ← для Overleaf и современных систем
\usepackage[russian]{babel}
\usepackage{matlab-prettifier}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{cases}

\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\graphicspath{{pictures/}}
% Устанавливаем шрифт, который точно поддерживает кириллицу
\renewcommand{\familydefault}{\rmdefault} % Сбрасываем на стандартный
\AtBeginDocument{\selectfont}             % Принудительно применяем шрифт
% ИЛИ
%\usepackage{libertine} % Linux Libertine — красивый шрифт с кириллицей
% ИЛИ
%\usepackage{dejavu} % DejaVu Serif — тоже хорош
%\usepackage[T2A]{fontenc}   %  это устанавливается авторматически

%%  Подключение стилевого файла отчета
\usepackage{kprj}

%%   Подключение пакета управления гиперссылками (только для pdftex)
\ifpdftex
\usepackage[unicode=true]{hyperref}
\hypersetup{pdfpagemode=UseNone, pdfstartview = FitR 0 0 200 1000}
\BlackColorLinks
\fi

%%%  Для подключения рисунков (разные форматы при разном компилировании)
\ifpdftex
% pdftex понимает форматы рисунков PNG, JPEG, PDF
\DeclareGraphicsExtensions{.pdf}
\else
% При создании DVI возможны практически все форматы, но EPS предпочтительнее
\DeclareGraphicsExtensions{.eps}
\fi


%%%    Тип работы
%\LabWork                      %   тип документа -- лабораторная работа
%\LabWorkNo{3}                 %   номер лабораторной работы
%\variant{}                   %   вариант лабораторной
\KursWork
%\KursProject
%\NIR
%\VKR
%\NKR


%%%  Данные для оформления

\author{А.А.~Сысоев}                 %   год выполнения работы
\title{Семантическая сегментация изображений рыб}   %  название
%\discipline{Качественная теория дифференциальных уравнений}              %  учебная дисциплина
\group{ФН12-71Б}                          %   группа
\faculty{Фундаментальные науки}         %   Факультет
\facultyshort{ФН}                       %   Факультет -- аббревиатура
\chair{Математическое моделирование}    %   кафедра
%\chairno{ФН-12}                         %   кафедра -- аббревиатура
%\chairhead{А.П.~Крищенко}              %   автор
%\authorfull{Курош Владимир Витальевич}  %   автор -- Фамилия, Имя, Отчество
\workyear{2025}                              %   зав. кафедрой
\chief{Д.А.~Фетисов}                     %   Руководитель работы
%\consultant{А.Ф.~Сидоров}               %   Консультант (если нужно)
%\inspector{Б.О.~Волков}                 %   Нормоконтролер
%\trend{учебная}                         %   Направление работы (указывается в задании)
%\themesource{кафедра}                   %   Источник темы (указывается в задании)

\equationnumbering{section}             %   если нумерация формул в пределах раздела (иначе единая нумерация)
\figurenumbering{section}              %   (аналогично для рисунков)
%%%   Оформление содержания, в текст вставлять командой \tableofcontents
\SkipContentsbreak                     %   Подавление разрыва страницы после содержания
\setcontentsname{Содержание}           %   Заголовок содержания
%\def\contsectionfont{\bfseries}        %   шрифт для разделов в содержании
%\def\contsubsectionfont{\sf}           %   шрифт для подразделов в содержании
%\setcounter{secnumdepth}{1}            %   глубина заголовков в содержании
%\onehalfspacing
\setcounter{secnumdepth}{3}

\begin{document}
	
	
	\maketitle
	\tableofcontents
	\newpage
	%\renewcommand{\labelenumi}{\asbuk{enumi})}
	\section{\centering{Введение}}
	\par В настоящее время сегментация изображений является одной из основных задач компьютерного зрения. Она показала высокую эффективность благодаря развитию методов глубокого обучения, в частности сверточных нейронных сетей. Сегментация изображений применяется в автономном вождении для распознавания элементов дорожной сцены, в медицинской визуализации ля выделения органов и патологий, а также при анализе спутниковых изображений ля классификации земной поверхности. Кроме того, семантическая сегментация используется в сельском хозяйстве и промышленности для автоматизации процессов мониторинга и анализа изображений.\newline
	В рамках данной работы рассматривается задача бинарной семантической сегментации изображений рыб, где требуется выделить области, соответствующие изображениям рыб.\\
	\textbf{Цель работы} --- разработка и обучение модели нейронной сети, способной решать задачу сематической сегментации изображении рыб.\\ \\
	Для достижения поставленной цели используются следующие задачи:
	\begin{enumerate}[-]
		\item Ислледование архитектуры нейронной сети U-net.
		\item  Подготовка и предварительная обработка набора изображений.
		\item Обучение модели на выбранном датасете.
		\item Оценка качества работы модели с использованием различных метрик.
		\item Анализ полученных результатов.
	\end{enumerate}
	
	Решение поставленной задачи позволит исследовать эффективность применения архитектуры U-net для сегментации изображений объектов. Полученные результаты могут быть использованы при дальнейшем изучении методов семантической сегментации.
	
	\newpage
	\section{\centering{Основная часть}}
	\subsection{\centering{Математическая формулировка задачи}}
	В общем случае задача сегментации – разделить изображение на фрагменты (группы пикселов) по некоторому общему критерию. В зависимости от критерия получаются разные задачи сегментации изображения.
	\begin{enumerate} 
		\item Извлечение объекта – выделение конкретного произвольного объекта,
		указанного пользователем или по-другому заданного. Например, пользователь
		может выделить объект ограничивающим прямоугольником или нарисовать
		контур объекта.
		\item Сегментация без учителя – разделение изображения на регионы, однородные
		по своим визуальным характеристикам и отличающиеся от соседних регионов.
		Например, нужно выделить области, соответствующие разным фрагментам на
		одежде человека
	\end{enumerate}
	
	Поскольку такие методы разбивают объекты обычно на несколько сегментов, то их еще называют методами пересегментации, потому что мы сегментируем чрезмерно по сравнению с тем, как хотелось бы. Отсюда приходим к понятию семантическая сегментация.
	\textbf{Семантическая сегментация} – попиксельная разметка изображения, где каждая метка соответствует определенному  классу объекта ~[\ref{lit:konushin}]. 
	При этом:
	\begin{enumerate}
		\item Разные пиксели одного объекта существенно отличаются друг от друга по
		признакам (яркости, цвету, текстуре окрестности).
		\item Единственное, что у них общее – «семантика» 
	\end{enumerate}
	Для формализации введем следующие  обозначения:
	\begin{enumerate}[-]
		\item $X = \{x_i\}_{i=1}^{N}$ — множество пикселей входного изображения;
		\item $Y = \{y_i\}_{i=1}^{N}$ — множество истинных меток пикселей;
		\item $\hat{Y} = \{\hat{y}_i\}_{i=1}^{N}$ — множество предсказанных меток;
		\item $y_i, \hat{y}_i \in \{0,1\}, \quad i = 1, \ldots, N$.
	\end{enumerate}
	
	Задача семантической сегментации заключается в нахождении такого отображения
	\begin{equation}
		f_\theta : X \rightarrow \hat{Y},
	\end{equation}
	где $f_\theta$ — нейронная сеть с параметрами $\theta$, которая для каждого пикселя входного изображения предсказывает его принадлежность к соответствующему классу.
	
	Обучение модели сводится к подбору параметров $\theta$, минимизирующих функцию потерь между предсказанными метками $\hat{Y}$ и истинной разметкой $Y$ на обучающей выборке.
	
	
	\newpage
	
	\subsection{\centering{Архитектура нейронной сети U-Net}}
	
	Для решения задачи семантической сегментации изображений в данной работе используется архитектура \textbf{U-Net}, которая доказала свою высокую эффективность в попиксельной разметке объектов~[\ref{lit:unet}]. Архитектура сочетает сжимательную и восстанавливающую части, обеспечивая точное выделение объектов даже при ограниченном количестве обучающих данных.
	
	Основным строительным блоком U-Net являются \textbf{сверточные слои}. Каждый сверточный слой применяет несколько фильтров размером $3 \times 3$, которые скользят по входному изображению и формируют карты признаков. Операция свёртки может быть записана следующим образом:
	
	\begin{equation}
		O_{x,y} = \sum_{i,j} W_{i,j} \, I_{x+i,\,y+j},
	\end{equation}
	
	где:
	\begin{enumerate}[-]
		\item $I$ — входные данные,
		\item $O$ — выходные данные,
		\item $W$ — ядро свёртки,
		\item $(i,j)$ пробегает все элементы ядра свёртки.
	\end{enumerate}
	
	Каждый фильтр выделяет определённые локальные признаки, такие как границы, текстуры и углы, позволяя сети постепенно изучать сложные визуальные характеристики.  
	\begin{figure}[H]
		\centering{\includegraphics[scale=0.5]{Convolutional_layer.png}}
		\caption{Операция свертки}
	\end{figure}
	
	После свёртки используется \textbf{функция активации ReLU}, определяемая как:
	\begin{equation}
		f(x) = \max(0, x),
	\end{equation}
	которая добавляет нелинейность в модель, позволяя нейросети аппроксимировать сложные функции. ReLU также предотвращает затухание градиента и ускоряет обучение.  
	\begin{figure}[H]
		\centering{\includegraphics[scale=0.4]{ReLU (2).png}}
		\caption{Функция активации}
	\end{figure}
	
	Используется \textbf{padding}, чтобы сохранить пространственные размеры карты признаков.
	
	Для уменьшения размерности карты признаков и увеличения области восприятия используется операция \textbf{max-pooling}. Обычно применяются окна $2 \times 2$, из которых выбирается максимальное значение. Это позволяет сети выделять более глобальные признаки, одновременно снижая вычислительные затраты.  
	\begin{figure}[H]
		\centering{\includegraphics[scale=0.4]{maxpool.png}}
		\caption{Pooling}
	\end{figure}
	
	В декодере необходимо восстановить пространственное разрешение карты признаков. Для этого используется операция \textbf{upsampling}, которая увеличивает размер карты признаков до исходного разрешения изображения и может уменьшать число каналов.  
	\begin{figure}[H]
		\centering{\includegraphics[scale=0.5]{Unsampling.png}}
		\caption{Upsampling}
	\end{figure}
	
	Для сохранения локальной информации и точной границы объектов применяются \textbf{skip connections}, которые соединяют соответствующие слои энкодера и декодера, чтобы избежать проблему затухания градиентов. Это позволяет декодеру использовать низкоуровневые признаки из энкодера вместе с высокоуровневыми признаками, улучшая точность сегментации мелких объектов~[\ref{lit:konushin}].
	\begin{figure}[H]
		\centering{\includegraphics[scale=0.6]{skip-connection.png}}
		\caption{Skip-Connection}
	\end{figure}
	
	\textbf{Энкодер}  состоит из последовательности блоков: две свёртки с двумя активациями ReLU, после которых следует max-pooling. На каждом уровне уменьшается пространственное разрешение и увеличивается количество каналов, что позволяет изучать более сложные признаки.
	
	\textbf{Декодер} выполняет upsampling карты признаков и последующие две свёртки с  двумя ReLU, при этом на каждом уровне добавляется информация с соответствующего слоя энкодера через skip connections. Это позволяет восстановить пространственное разрешение и точно локализовать объекты.
	
	\textbf{Выходной слой} состоит из свёртки $1 \times 1$, которая преобразует карту признаков в маску сегментации:
	
	Таким образом, U-Net объединяет локальные признаки низкого уровня с глобальными признаками высокого уровня, обеспечивая точную попиксельную сегментацию.
	\begin{figure}[H]
		\centering{\includegraphics[scale=0.45]{unet.png}}
		\caption{Архитектура U-net}
	\end{figure}
	\newpage
	
	\subsection{\centering{Подготовка данных}}
	
	В данной работе для обучения и оценки модели семантической сегментации используется набор данных изображений рыб, содержащий 9000 пар изображений и соответствующих им масок. Исходные изображения имеют различное пространственное разрешение  $590 \times 445$ пикселей и относятся к девяти различным классам рыб.
	
	Каждое изображение сопровождается бинарной маской, задающей принадлежность пикселей к объекту или фону. Таким образом, задача формулируется как задача бинарной семантической сегментации, где для каждого пикселя необходимо определить его принадлежность к классу объекта.
	
	Для обеспечения корректной работы нейронной сети и возможности пакетной обработки данных все изображения и маски приводятся к фиксированному размеру $224 \times 224$ пикселя. Выбор данного размера является компромиссом между сохранением пространственной информации и снижением вычислительной сложности модели, что особенно важно при использовании архитектуры U-Net.
	
	Перед подачей изображений в модель выполняется их преобразование в тензорный формат и нормализация по каналам RGB. Нормализация проводится с использованием средних значений и стандартных отклонений, вычисленных для набора ImageNet.
	
	Для масок сегментации применяется масштабирование с использованием ближайшего соседа, что позволяет сохранить дискретный характер меток и избежать появления некорректных промежуточных значений. Маски также преобразуются в тензорный формат без дополнительной нормализации.
	
	Приведение изображений к фиксированному размеру позволяет уменьшить пространственную размерность входных данных более чем в 5 раз по сравнению с исходным разрешением. Хотя количество обучаемых параметров сети определяется архитектурой и не зависит от размера входа, такое преобразование существенно снижает объём вычислений, требования к памяти и ускоряет процесс обучения модели.
	
	\textbf{Деление на выборки}
	
	В глубоком обучении для корректного обучения и объективной оценки качества модели принято разделять исходный набор данных на несколько непересекающихся выборок:
	\begin{enumerate}[-]
		\item \textbf{Обучающая выборка} — используется для непосредственного обучения модели и оптимизации её параметров.
		\item \textbf{Валидационная выборка} — предназначена для промежуточной оценки качества модели в процессе обучения, подбора гиперпараметров и контроля переобучения.
		\item \textbf{Тестовая выборка} — применяется для итоговой оценки качества модели и проверки её обобщающей способности на ранее не использованных данных.
	\end{enumerate}
	
	В рамках данной работы исходный датасет был разделён на обучающую, валидационную и тестовую выборки с использованием функции \texttt{random\_split} библиотеки PyTorch. На первом этапе 70\% данных были выделены для обучения модели, а оставшиеся 30\% — для последующего разбиения. Далее данная часть была разделена на валидационную и тестовую выборки в пропорции 60\% и 40\%, что соответствует 18\% и 12\% от общего объёма данных соответственно.  Такое разбиение позволяет эффективно контролировать процесс обучения и объективно оценивать её качество на отложенных данных.
	
	\subsection{\centering{Метрики оценки качества модели}}
	
	Для оценки качества работы модели семантической сегментации в данной работе используются две основные метрики: точность классификации по пикселям (Accuracy) и коэффициент пересечения и объединения (Intersection over Union, IoU). Обе метрики вычисляются на основе сравнения предсказанных и истинных меток пикселей.
	
	Предсказания модели представляют собой значения вероятностей принадлежности пикселей к классу объекта. Для получения бинарной маски используется пороговая функция, согласно которой пиксель относится к классу объекта, если предсказанная вероятность превышает заданное пороговое значение.
	
	\textbf{IoU через множества пикселей.}
	
	Пусть $A$ — множество пикселей, принадлежащих объекту согласно истинной разметке (истинная маска), а $B$ — множество пикселей, отнесённых моделью к объекту (предсказанная маска). Тогда метрика Intersection over Union определяется как отношение мощности пересечения этих множеств к мощности их объединения:
	\begin{equation}
		\mathrm{IoU} = \frac{|A \cap B|}{|A \cup B|}.
	\end{equation}
	
	Эта формулировка наглядно показывает степень совпадения предсказанной и истинной области объекта: числитель отражает количество пикселей, корректно выделенных моделью, а знаменатель — общую область, охватывающую как истинный объект, так и его предсказание~[\ref{lit:gIoU}].
	
	\textbf{Матрица ошибок.}
	
	Для формального представления метрик введём элементы матрицы ошибок:
	\begin{enumerate}[-]
		\item $TP$ (True Positive) — количество пикселей, принадлежащих $A \cap B$;
		\item $FP$ (False Positive) — количество пикселей, принадлежащих $B \setminus A$;
		\item $FN$ (False Negative) — количество пикселей, принадлежащих $A \setminus B$;
		\item $TN$ (True Negative) — количество пикселей, не принадлежащих ни $A$, ни $B$.
	\end{enumerate}
	
	\textbf{Accuracy.}
	
	Метрика Accuracy определяет долю правильно классифицированных пикселей относительно общего числа пикселей изображения и вычисляется по формуле:
	\begin{equation}
		\mathrm{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}.
	\end{equation}
	
	Данная метрика является простой и наглядной, однако в задачах семантической сегментации она может быть недостаточно информативной. Это связано с тем, что фон на большинстве изображений занимает значительно большую площадь по сравнению с объектом, который нужно правильно сегментировать. В результате Accuracy может быть завышена даже при неудовлетворительном качестве сегментации объекта.
	
	\textbf{Intersection over Union (IoU) через матрицу ошибок.}
	
	С использованием элементов матрицы ошибок метрика IoU может быть представлена следующим образом:
	\begin{equation}
		\mathrm{IoU} = \frac{TP}{TP + FP + FN}.
	\end{equation}
	
	В отличие от Accuracy, метрика IoU не учитывает количество истинно отрицательных пикселей ($TN$), что делает её более устойчивой к дисбалансу классов и более чувствительной к качеству сегментации именно объекта интереса~[\ref{lit:konushin}].
	
	\textbf{Сравнение метрик}
	
	Использование Accuracy позволяет оценить общее качество попиксельной классификации, однако для задач семантической сегментации более информативной является метрика IoU. Она напрямую отражает качество совпадения предсказанной и истинной областей объекта и широко используется в качестве основной метрики в задачах сегментации изображений. В данной работе IoU рассматривается как ключевая метрика для анализа эффективности модели.
	
	\subsection{\centering{Функция потерь}}
	
	Для обучения модели семантической сегментации в данной работе используется функция потерь Dice loss, основанная на коэффициенте сходства Дайса. В отличие от метрик качества, функция потерь должна быть дифференцируемой, так как именно по её значению осуществляется оптимизация параметров нейронной сети с использованием алгоритма обратного распространения ошибки.
	
	Классический коэффициент Дайса определяется через элементы матрицы ошибок следующим образом:
	\begin{equation}
		\mathrm{Dice} = \frac{2TP}{2TP + FP + FN}.
	\end{equation}
	
	Поскольку операции пороговой бинаризации не являются дифференцируемыми, при вычислении Dice loss используются непрерывные предсказания модели в виде вероятностей, получаемых с помощью сигмоидальной функции активации. Это позволяет сохранить дифференцируемость функции потерь и применять градиентные методы оптимизации~[\ref{lit:dice}].
	
	В данной работе функция потерь определяется как
	\begin{equation}
		\mathcal{L}_{Dice} = 1 - \mathrm{Dice},
	\end{equation}
	что соответствует минимизации несоответствия между предсказанной и истинной масками сегментации. Использование Dice loss особенно эффективно в задачах с дисбалансом классов, так как она напрямую ориентирована на качество сегментации объекта и слабо зависит от количества фоновых пикселей.
	
	\subsection{\centering{Результаты эксперимента}}
	
	В результате обучения модели семантической сегментации на основе архитектуры U-Net была проведена оценка её качества на тестовой выборке, не участвовавшей в процессе обучения и настройки параметров модели. Для количественной оценки использовались метрики Accuracy и Intersection over Union (IoU).
	
	Результаты оценки качества модели на тестовой выборке у Accuracy составляет 0.9857, а у IoU --- 0.9156.
	
	Высокое значение метрики Accuracy свидетельствует о корректной попиксельной классификации изображений в целом. В то же время значение метрики IoU, превышающее 0.9, указывает на хорошее совпадение предсказанных и истинных масок объектов, что является более строгим и информативным показателем качества семантической сегментации.
	
	
	
	
	Для анализа процесса обучения были построены графики изменения значения функции потерь и метрик качества на обучающей и валидационной выборках в зависимости от номера эпохи. Анализ данных графиков позволяет оценить сходимость модели и выявить возможные признаки переобучения.
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=1.0\textwidth]{metricsloss.png}
		\caption{Метрики и функция потерь на тренировочной и валидационной выборке}
	\end{figure}
	
	Представленные графики демонстрируют устойчивое снижение значения функции потерь и рост метрик качества на протяжении обучения. Близость кривых для обучающей и валидационной выборок свидетельствует об отсутствии выраженного переобучения и хорошей обобщающей способности модели.
	
	\newpage
	\section{\centering{Заключение}}
	
	В рамках данной курсовой работы была рассмотрена задача семантической сегментации изображений рыб с использованием методов глубокого обучения. Для решения поставленной задачи была выбрана и реализована архитектура сверточной нейронной сети U-Net, показавшая высокую эффективность в задачах попиксельной классификации изображений.
	
	В ходе работы была выполнена подготовка и анализ набора данных, включающая нормализацию изображений, приведение их к фиксированному размеру и разделение на обучающую, валидационную и тестовую выборки. Была проведена реализация процесса обучения модели с использованием функции потерь Dice loss и оценка качества сегментации с помощью метрик Accuracy и Intersection over Union.
	
	Экспериментальные результаты показали, что обученная модель демонстрирует высокое качество сегментации на тестовых данных. Значения метрик Accuracy и IoU подтверждают способность модели корректно выделять объекты и сохранять их границы даже при наличии вариаций формы и условий съёмки.
	
	В качестве направлений дальнейшего развития работы можно рассмотреть использование методов регуляризации, таких как Dropout и Batch Normalization, для повышения устойчивости модели и снижения риска переобучения.
	
	Полученные результаты свидетельствуют о целесообразности применения архитектуры U-Net для решения задач семантической сегментации изображений биологических объектов.
	\newpage
	
	\section{\centering{Список литературы}}
	\begin{enumerate}
		\item \label{lit:konushin} Конушин А.С. Компьютерное зрение. --- М.:МГУ, 2010. --- 328 с.
		
		\item \label{lit:unet} Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional Networks for Biomedical Image Segmentation
		[Электонный ресурс]. --- 2015. --- URL: \\ https://arxiv.org/abs/1505.04597
		\item \label{lit:gIoU} Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian Reid, Silvio Savarese. Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression
		[Электонный ресурс]. --- 2019. --- URL: \\
		https://arxiv.org/abs/1902.09630
		\item \label{lit:dice} Chen Shen, Holger R. Roth, Hirohisa Oda, Masahiro Oda, Yuichiro Hayashi, Kazunari Misawa, Kensaku Mori. On the influence of Dice loss function in multi-class organ segmentation of abdominal CT using 3D fully convolutional networks  [Электонный ресурс]. --- 2018. --- URL: 
		https://arxiv.org/abs/1801.05912
	\end{enumerate}
	\newpage
	\section{\centering{Приложение}}
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.85\textwidth]{test.png}
		\caption{Предсказания модели на тестовой выборке}
	\end{figure}
\end{document}